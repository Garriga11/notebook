{"cells":[{"cell_type":"markdown","id":"24ff1f19-565c-4b97-a63e-e93ec228bccb","metadata":{},"source":["#odpy, a computer vision model, built from scratch and implememted into this notebook for experimental purposes. \n","\n","A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about that data.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0222f629-dd0b-4c8e-bc73-605022bf5295","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Running experiment with ID:  0f593166d6274a6b8e5fbc5305df3965\n","Epoch 1/5\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.2641 - loss: 5.5400 - val_accuracy: 0.3500 - val_loss: 1.9117\n","Epoch 2/5\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.4437 - loss: 1.3212 - val_accuracy: 0.2500 - val_loss: 1.3364\n","Epoch 3/5\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.3836 - loss: 1.1819 - val_accuracy: 0.2500 - val_loss: 1.1354\n","Epoch 4/5\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.3680 - loss: 1.0822 - val_accuracy: 0.2500 - val_loss: 1.1956\n","Epoch 5/5\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.4031 - loss: 1.0834 - val_accuracy: 0.4000 - val_loss: 1.1595\n"]},{"name":"stderr","output_type":"stream","text":["2024/10/27 11:47:57 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n","2024/10/27 11:48:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n","Registered model 'TireDefectModel' already exists. Creating a new version of this model...\n","Created version '5' of model 'TireDefectModel'.\n"]},{"ename":"ValueError","evalue":"Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=tire_defect_detection_model.pbtxt.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved in run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[43mtrain_and_log_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Start your training job with `start_run()`\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run() \u001b[38;5;28;01mas\u001b[39;00m run:\n","Cell \u001b[1;32mIn[7], line 73\u001b[0m, in \u001b[0;36mtrain_and_log_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtire_defect_detection_model.pbtxt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved in run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:114\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[0;32m    112\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[0;32m    113\u001b[0m     )\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m )\n","\u001b[1;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=tire_defect_detection_model.pbtxt."]}],"source":["import mlflow.sklearn\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from mlflow.models.signature import infer_signature\n","import mlflow\n","import mlflow.tensorflow\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import mlflow\n","import mlflow.tensorflow\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","\n","# Set experiment name in MLflow (it will create if it doesn't exist)\n","EXPERIMENT_NAME = \"Tire Defect Detection\"\n","mlflow.set_experiment(EXPERIMENT_NAME)\n","\n","# Load or generate your data (using random data here for demo)\n","def load_data():\n","    # Dummy dataset, replace with actual data loading\n","    train_images = np.random.rand(100, 224, 224, 3)  # Replace with actual images\n","    train_labels = np.random.randint(0, 3, (100, 1))  # Replace with actual labels\n","    return train_images, train_labels\n","\n","# Example simple CNN model\n","def build_model():\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(64, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(3, activation='softmax')  # Assuming 3 classes (bentRim, goodTire, cracking)\n","    ])\n","    return model\n","\n","# Training and logging the model in MLflow\n","def train_and_log_model():\n","    train_images, train_labels = load_data()\n","\n","    # Prepare the model\n","    model = build_model()\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    # MLflow logging\n","    with mlflow.start_run() as run:\n","        print(\"Running experiment with ID: \", run.info.run_id)\n","\n","        # Log parameters (you can log hyperparameters)\n","        mlflow.log_param(\"optimizer\", \"adam\")\n","        mlflow.log_param(\"loss\", \"sparse_categorical_crossentropy\")\n","        mlflow.log_param(\"epochs\", 5)\n","        mlflow.log_param(\"batch_size\", 32)\n","\n","        # Train the model and log training metrics\n","        history = model.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.2)\n","\n","        # Log the model\n","        mlflow.tensorflow.log_model(model, artifact_path=\"model\", registered_model_name=\"TireDefectModel\")\n","\n","        # Log metrics (training accuracy, loss, etc.)\n","        for epoch, acc in enumerate(history.history['accuracy']):\n","            mlflow.log_metric(\"accuracy\", acc, step=epoch)\n","        for epoch, loss in enumerate(history.history['loss']):\n","            mlflow.log_metric(\"loss\", loss, step=epoch)\n","\n","        # Save the final model\n","        model.save(\"tire_defect_detection_model.pbtxt\")\n","        print(f\"Model saved in run {run.info.run_id}\")\n","\n","if __name__ == \"__main__\":\n","    train_and_log_model()\n","\n","\n","\n","# Start your training job with `start_run()`\n","with mlflow.start_run() as run:\n","\n","    lr = LogisticRegression()\n","    X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\n","    y = np.array([0, 0, 1, 1, 1, 0])\n","    lr.fit(X, y)\n","    score = lr.score(X, y)\n","    signature = infer_signature(X, y)\n","\n","    # Activate the MLFlow logging API to log your training job metrics\n","    print(\"test log_metrics.\")\n","    mlflow.log_metric(\"score\", score)\n","\n","    # Activate the MLFlow logging API to log your training job parameters\n","    print(\"test log_params.\")\n","    mlflow.log_param(\"alpha\", \"alpha\")\n","    print(\"All done\")"]},{"cell_type":"code","execution_count":6,"id":"6d7633b3","metadata":{},"outputs":[{"ename":"OSError","evalue":"SavedModel file does not exist at: odpy/mlruns/models/TireDefectModel/version-1/meta.yaml\\{saved_model.pbtxt|saved_model.pb}","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 1: Load the model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124modpy/mlruns/models/TireDefectModel/version-1/meta.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with your model's path\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 2: Load and preprocess the test image\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:912\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    911\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 912\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:1016\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m   1012\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m   1015\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1016\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1018\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:59\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     62\u001b[0m       path_helpers\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     63\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     64\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n","File \u001b[1;32mc:\\Users\\garri\\odpy\\odpy\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:119\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m saved_model\n","\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: odpy/mlruns/models/TireDefectModel/version-1/meta.yaml\\{saved_model.pbtxt|saved_model.pb}"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Step 1: Load the model\n","model_path = \"odpy/mlruns/models/TireDefectModel/version-1/meta.yaml\"  # Update with your model's path\n","model = tf.saved_model.load(model_path)\n","print(\"Model loaded successfully.\")\n","\n","# Step 2: Load and preprocess the test image\n","def load_image(image_path):\n","    img = cv2.imread(image_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img_resized = cv2.resize(img_rgb, (640, 640))  # Resize to model's input size\n","    img_array = np.array(img_resized) / 255.0  # Normalize\n","    return img_rgb, img_array[np.newaxis, ...]  # Add batch dimension\n","\n","image_path = \"odpy/images/bentRim.jpg\"  # Update with your test image path\n","original_img, preprocessed_img = load_image(image_path)\n","print(\"Test image loaded and preprocessed.\")\n","\n","# Step 3: Make predictions\n","def get_predictions(model, image):\n","    outputs = model(image)\n","    predictions = outputs['detection_boxes'][0].numpy()\n","    scores = outputs['detection_scores'][0].numpy()\n","    classes = outputs['detection_classes'][0].numpy().astype(int)\n","    return predictions, scores, classes\n","\n","predictions, scores, classes = get_predictions(model, preprocessed_img)\n","\n","# Step 4: Filter predictions by confidence threshold\n","confidence_threshold = 0.5\n","filtered_boxes = []\n","filtered_labels = []\n","\n","for i, score in enumerate(scores):\n","    if score >= confidence_threshold:\n","        box = predictions[i]\n","        filtered_boxes.append(box)\n","        filtered_labels.append(classes[i])  # Replace with label names if available\n","print(f\"Filtered {len(filtered_boxes)} boxes with confidence >= {confidence_threshold}\")\n","\n","# Step 5: Visualize predictions\n","def draw_boxes(image, boxes, labels):\n","    fig, ax = plt.subplots(1)\n","    ax.imshow(image)\n","\n","    for box, label in zip(boxes, labels):\n","        ymin, xmin, ymax, xmax = box\n","        rect = patches.Rectangle(\n","            (xmin * image.shape[1], ymin * image.shape[0]),\n","            (xmax - xmin) * image.shape[1],\n","            (ymax - ymin) * image.shape[0],\n","            linewidth=2, edgecolor='r', facecolor='none'\n","        )\n","        ax.add_patch(rect)\n","        ax.text(xmin * image.shape[1], ymin * image.shape[0] - 10, str(label), color='red', fontsize=12)\n","    \n","    plt.axis('off')\n","    plt.show()\n","\n","draw_boxes(original_img, filtered_boxes, filtered_labels)\n","\n"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"8af33217-4058-4613-84d6-007fe19193d6","default_lakehouse_name":"odpy","default_lakehouse_workspace_id":"658de4da-6805-4df0-9df3-ae73307a52ab"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"odpy","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"orig_nbformat":4,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
